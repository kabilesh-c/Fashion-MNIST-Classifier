# Fashion MNIST Image Classification

## Project Overview

This project demonstrates how to build an image classification model using the Fashion MNIST dataset. The goal is to classify images of clothing items into one of ten categories. The project covers dataset loading, preprocessing, model design, training, evaluation, and result interpretation.

## Dataset Description

The Fashion MNIST dataset is provided by TensorFlow and contains 60,000 grayscale images for training and 10,000 images for testing. Each image has a size of 28 by 28 pixels. The dataset contains the following ten categories:

1. T shirt/top
2. Trouser
3. Pullover
4. Dress
5. Coat
6. Sandal
7. Shirt
8. Sneaker
9. Bag
10. Ankle boot

The dataset is widely used for benchmarking image classification algorithms and provides a simple, well-labeled dataset that is suitable for beginners.

## Data Preprocessing

The preprocessing steps include:

1. Normalizing the image pixel values from a range of 0 to 255 to a range of 0 to 1.
2. Reshaping the images to add a channel dimension so that they can be used in a convolutional neural network.
3. Keeping the labels as integers, suitable for sparse categorical classification.

These steps ensure that the data is ready for training a deep learning model.

## Model Architecture

The model is built using TensorFlow and Keras. It consists of the following layers:

1. Input layer that reshapes the image to include one channel.
2. Convolutional layer with 32 filters and a kernel size of 3 by 3, using the ReLU activation function.
3. Max pooling layer with a pool size of 2 by 2.
4. Convolutional layer with 64 filters and a kernel size of 3 by 3, using the ReLU activation function.
5. Max pooling layer with a pool size of 2 by 2.
6. Flatten layer that converts the image to a one-dimensional array.
7. Dense layer with 64 neurons and ReLU activation.
8. Output layer with 10 neurons and softmax activation for classification.

The model is compiled using the Adam optimizer, sparse categorical crossentropy as the loss function, and accuracy as the evaluation metric.

## Model Training

The model is trained for 10 epochs using the training set. Validation is performed on the test set at each epoch. The model learns to classify images into one of the ten categories by minimizing the classification error.

## Results

After training, the model achieves a test accuracy of 91.02 percent. This means that the model correctly classifies 91 out of 100 images from the test set. The training and validation accuracy and loss graphs demonstrate how the model improves over time.

Below is the visualization of the training process.

Training and validation accuracy plot


<img width="576" height="432" alt="image" src="https://github.com/user-attachments/assets/d01b017b-7ddc-470f-a014-6f9836dadb81" />


 Training and validation loss plot


<img width="576" height="432" alt="image" src="https://github.com/user-attachments/assets/60235907-fa10-45c2-a597-97db56d1d71c" />


Below are example predictions from the test dataset. The modelâ€™s predicted label is shown along with the true label.

Example predictions visualization

<img width="1449" height="594" alt="image" src="https://github.com/user-attachments/assets/7bb6964d-a703-40fd-a350-6ae9fa64f864" />


## Model Saving

The trained model is saved in the Keras format as fashion\_mnist\_model.keras. This allows the model to be easily loaded and used for further inference or analysis.

## How to Run

1. Open the provided notebook in Google Colab.
2. Run each cell in order to load the dataset, preprocess the data, build the model, and train it.
3. After training, use the evaluation cell to see the final test accuracy.
4. Run the visualization cells to see example predictions.
5. Save the model using the provided code cell.

## Conclusion

This project demonstrates the fundamental steps in building an image classification system using convolutional neural networks. It covers data loading, preprocessing, model building, training, evaluation, and result interpretation. With a test accuracy above 90 percent, the model performs well on this benchmark dataset and provides a solid foundation for exploring more advanced computer vision projects.
